{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f28f4eb-04a4-4fcb-a8fb-edd9bb1da9f8",
   "metadata": {},
   "source": [
    "## Step 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3e67b-4223-4755-b7f2-0b7718ba0218",
   "metadata": {},
   "source": [
    "### 1.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeca27-793b-4000-9f6b-b6a51debd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to your desired directory\n",
    "# os.chdir('/common/users/$USER/df_words') # change $USER to netid\n",
    "\n",
    "# Confirm it's changed\n",
    "# print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "images_dir = '.\\iam_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745fd7-48a8-461e-9780-b5e110b5b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "label_file_path = images_dir + '\\words.txt'\n",
    "image_file_path = images_dir + '\\iam_words\\words'\n",
    "\n",
    "data = []\n",
    "with open(label_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for idx, line in enumerate(lines[18:]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"Processing line {idx}\")\n",
    "    row = []\n",
    "    tokens = line.strip().split()\n",
    "    if len(tokens) < 2:\n",
    "        continue\n",
    "\n",
    "    subfolder = tokens[0].split('-')[0]\n",
    "    subfolder2 = subfolder + \"-\" + tokens[0].split('-')[1]\n",
    "    image_file_name = subfolder + \"\\\\\" + subfolder2 + \"\\\\\" + tokens[0] + \".png\"\n",
    "    image_path = os.path.join(image_file_path, image_file_name)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.size[0] >= 10 and img.size[1] >= 10:\n",
    "                img_rgb = img.convert(\"RGB\")  # Convert to RGB\n",
    "                img_copy = img_rgb.copy()     # Copy after conversion\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Image file not found: {image_file_path}. Error: {e}\")\n",
    "        continue\n",
    "    except Image.UnidentifiedImageError as e:\n",
    "        print(f\"Unidentified image error for file {image_file_path}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image file {image_file_path}: {e}\")\n",
    "        continue\n",
    "    row = [image_path, tokens[1], tokens[2], tokens[-1], img_copy]\n",
    "    # if len(row) != 10:\n",
    "    #     print(f\"Row length mismatch: {len(row)} elements in row: {row}\")\n",
    "    #     continue\n",
    "    data.append(row)\n",
    "\n",
    "\n",
    "print(f\"Length of a row in data: {len(data[0])}\")  # Should print 10\n",
    "\n",
    "print(data[0])\n",
    "loaded = pd.DataFrame(data, columns=['image_id', 'segmentation_status', 'graylevel','text', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410eee9-1cdb-4dae-b9eb-b8af757900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded.copy()\n",
    "print(loaded_dfwords.info())\n",
    "print(loaded_dfwords.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd39ed-8ff9-47bb-815e-254681d06606",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a925a60-56a3-401e-98a6-b45d5ebfb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(df, row):\n",
    "    # plt.imshow(df.iloc[row]['image'], cmap='gray')\n",
    "    img = Image.open(df.iloc[row]['image_id'])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(loaded_dfwords, 10)  # Show the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada98afd-f656-45dc-ab5f-edc0f3d24ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Patter for all Special characters\n",
    "special_char_pattern = r'[^a-zA-Z0-9\\s]'  # Matches anything not alphanumeric or whitespace\n",
    "\n",
    "# Select rows with special characters\n",
    "special_char_rows = loaded_dfwords[loaded_dfwords['text'].str.contains(special_char_pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497d1fb-a7fe-4d86-b527-b2d221ee4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4040a5a-2c6b-4942-81cc-78890fa1eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_pattern = r'^[\\w\\s\\.,!?;:\\-+*/=()\\[\\]{}<>@#\\$%^&_\\'\"\\t\\n]+$'\n",
    "mask = ~loaded_dfwords['text'].str.contains(allowed_pattern, regex=True)\n",
    "non_standard_rows = loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d01cd-5002-49da-bc64-e19ea134d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_standard_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6dc5b-8f26-40fe-9d3c-0dca648f4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = loaded_dfwords['text'].str.contains(r'\\\\', regex=True)\n",
    "check_rows= loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13879fc-095f-43b7-ad97-887bedc2fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords['text'] = loaded_dfwords['text'].str.replace('\\\\/', '/', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03450d73-c3c6-479e-a3a6-5ea1cb8401d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~loaded_dfwords['text'].str.contains(allowed_pattern, regex=True)\n",
    "non_standard_rows2 = loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fed34-7601-4ea8-9f19-22450677186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words with special character:\", len(non_standard_rows2), \", Percentage: \", len(non_standard_rows2)/len(loaded_dfwords))\n",
    "print(\"Images with special character:\", len(non_standard_rows2['image_id'].unique()), \", Percentage: \", len(non_standard_rows2['image_id'].unique())/len(loaded_dfwords['image_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc85fe7-8168-4412-b128-86fcf0998657",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords=loaded_dfwords[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254f0e8-c135-45cc-957f-1ab94811e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbba6b3-8e22-4d0b-8811-10d61f31c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm there is no special characters\n",
    "count_matching = loaded_dfwords['text'].str.contains(allowed_pattern, regex=True, na=False).sum()\n",
    "print(f\"Number of rows with allowed characters: {count_matching}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875862b-c305-43e9-a435-94aebcd102ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^[^a-zA-Z0-9]+$'  # Matches strings with no alphanumeric chars at all\n",
    "non_alnum_rows = loaded_dfwords[loaded_dfwords['text'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f207856-f41e-42f2-919a-a0927287af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d632bdd-eee0-4ead-91cd-6db461c1d533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_alnum_rows.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06f40e-6f89-41b8-9ab3-78670b26c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check other rows that have only characters\n",
    "pattern = r'^[^a-zA-Z0-9]+$'  # Matches strings with no alphanumeric chars at all\n",
    "non_alnum_rows2 = loaded_dfwords[loaded_dfwords['text'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d544441-7107-493b-8d2d-877f20709bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alnum_rows2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alnum_rows2['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32292d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these to match the other imgur dataset preprocessing (it also removes all instances of text as '.' due to incorrect labels)\n",
    "only_period_rows= loaded_dfwords[loaded_dfwords['text'] == '.']\n",
    "loaded_dfwords = loaded_dfwords[loaded_dfwords['text'] != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyphen_row = loaded_dfwords[loaded_dfwords['text'] == '-----------------------------------------------------']\n",
    "id = hyphen_row['image_id'].to_string()\n",
    "print(id)\n",
    "print(\"image:\", id.split('\\\\')[-1])  # Print the image file name\n",
    "r = loaded_dfwords[loaded_dfwords['image_id'] == '.\\iam_words\\iam_words\\words\\p02\\p02-109\\p02-109-01-00.png']  # Get the row with the hyphen image\n",
    "print(r)\n",
    "show_image(r, 0)  # Show the hyphen image\n",
    "# show_image(loaded_dfwords, hyphen_row.index[0] + 1)  # Show the hyphen image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477aa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded_dfwords[loaded_dfwords['text'] != '-----------------------------------------------------']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded_dfwords.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf92f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289af3a-c757-493b-a5ba-ed274414bfc1",
   "metadata": {},
   "source": [
    "### 1.3 Splitting the Data into Training and Testing Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35baa5f-4657-4390-b532-ee7ab81b6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get unique groups\n",
    "unique_images = loaded_dfwords['image_id'].unique()\n",
    "\n",
    "\n",
    "# Randomly select 10% for test \n",
    "np.random.seed(42)\n",
    "test_images = np.random.choice(unique_images, \n",
    "                              size=int(len(unique_images)*0.2), \n",
    "                              replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a2758-4458-4533-b933-d77fe786cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = loaded_dfwords[loaded_dfwords['image_id'].isin(test_images)]\n",
    "training_df = loaded_dfwords[~loaded_dfwords['image_id'].isin(test_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e759d-5504-4c81-a68c-f7154c2eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words in Train Dataset:\", len(training_df), \", Percentage: \", len(training_df)/len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6e047-453c-409e-98de-ce5ce73a9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words in Test Dataset:\", len(test_df), \", Percentage: \", len(test_df)/len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea129db7-c914-46cb-8f3c-79cd8390339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd7550-02d4-4e43-8e9c-71cf189b9852",
   "metadata": {},
   "source": [
    "### 1.4 Splitting the Training Data into Training and Validation Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfb5e0-bc23-4659-97ae-765f5de49da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "train_df, eval_df = train_test_split(training_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6034ff9-bff3-475e-9da5-fee4ad95e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b3ce4-773d-4aea-916c-5eace4a1c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0e416-9ec2-466a-b28e-68a6856ea6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(train_df.iloc[0])\n",
    "show_image(train_df, 0)\n",
    "\n",
    "print(eval_df.iloc[0])\n",
    "show_image(eval_df, 0)\n",
    "\n",
    "print(test_df.iloc[0])\n",
    "show_image(test_df, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd5924-832d-4d2e-8a2a-f00cc8ff8cee",
   "metadata": {},
   "source": [
    "### 1.5 Saving the Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1113e1-f76e-49c5-aee4-6252107abdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df\n",
    "# train_df_copy = training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d34aa-944d-44d5-beee-731a5bb63d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy.drop('image', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca38c2-d716-4b17-80c9-dc8d6b57a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy.drop('image', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343bf93-f5b0-45a7-81d9-ba710fd3401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51113129-3240-404b-8ef7-20901c02bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ece9d-acc9-4cc0-8e48-a8c70286d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy.reset_index()\n",
    "# test_df_copy['word_id'] = test_df_copy.index\n",
    "# test_df_copy = test_df_copy.drop('index', axis=1)\n",
    "# test_df_copy = test_df_copy.drop('level_0', axis=1)\n",
    "\n",
    "# print(test_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8b101-6474-41ad-bafd-36de0412fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy.reset_index()\n",
    "# train_df_copy['word_id'] = train_df_copy.index\n",
    "# train_df_copy = train_df_copy.drop('index', axis=1)\n",
    "# train_df_copy = train_df_copy.drop('level_0', axis=1)\n",
    "\n",
    "# print(train_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53d1c0-2cc1-4007-b88e-4e52b990fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy[[train_df_copy.columns[2]] + train_df_copy.columns[:2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb5fe2-91b8-440b-a15c-ac9b0ac103ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy[[test_df_copy.columns[2]] + test_df_copy.columns[:2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e152858-71db-4fc7-93a9-a7dfa07c4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc20aa-8f0f-4327-8127-2e11fc0ffbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf5e9e-3de7-46ad-b458-4531b8a09a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c3dcc-f18b-4ad8-9ba0-86937200f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b327d-03a4-4c20-a875-2e192b81ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.to_csv('df_test.csv', index=False)\n",
    "# train_df_copy.to_csv('df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53584f-9d1b-495b-b632-b8bf0c6c7ae9",
   "metadata": {},
   "source": [
    "## Step 2. Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9affb4-9a40-494f-b130-a552abc03e90",
   "metadata": {},
   "source": [
    "### 2.1 Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67088bd-67e2-4f51-90a1-3a0d781cd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c62a4e-0326-4fce-93cd-56df14603a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get base model\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-stage1')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-small-stage1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854c0aa-ab24-4f49-acde-a7dac11a7d21",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the Training Data into Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1dba6-94b3-442c-9a3e-92b86fd8cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class StyleDataset(Dataset):\n",
    "    def __init__(self, df, processor, max_target_length=512):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      try:\n",
    "          text = self.df['text'][idx]\n",
    "          if not isinstance(text, str) or not text.strip():\n",
    "              raise ValueError(f\"Invalid text at index {idx}: {repr(text)}\")\n",
    "          image_id = self.df['image_id'][idx]\n",
    "          try:\n",
    "              image = self.df['image'][idx]\n",
    "          except Exception as e:\n",
    "              raise ValueError(f\"Failed to load image for ID {image_id} at index {idx}\") from e\n",
    "          try:\n",
    "              pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "          except Exception as e:\n",
    "              raise ValueError(f\"Image processing failed at index {idx}\") from e\n",
    "\n",
    "          if torch.isnan(pixel_values).any() or torch.isinf(pixel_values).any():\n",
    "              raise ValueError(f\"Invalid pixel values (NaN/inf) at index {idx}\")\n",
    "          try:\n",
    "              labels = self.processor.tokenizer(\n",
    "                  text,\n",
    "                  padding=\"max_length\",\n",
    "                  max_length=self.max_target_length\n",
    "              ).input_ids\n",
    "          except Exception as e:\n",
    "              raise ValueError(f\"Tokenization failed for text at index {idx}\") from e\n",
    "\n",
    "          # Replace pad_token_id with -100 for loss masking\n",
    "          labels = [\n",
    "              label if label != self.processor.tokenizer.pad_token_id else -100\n",
    "              for label in labels\n",
    "          ]\n",
    "          encoding = {\n",
    "              \"pixel_values\": pixel_values.squeeze(),\n",
    "              \"labels\": torch.tensor(labels)\n",
    "          }\n",
    "\n",
    "          if encoding[\"pixel_values\"].dim() != 3:\n",
    "              raise ValueError(f\"Invalid pixel_values shape at index {idx}\")\n",
    "\n",
    "          if encoding[\"labels\"].numel() != self.max_target_length:\n",
    "              raise ValueError(f\"Labels length mismatch at index {idx}\")\n",
    "\n",
    "          return encoding\n",
    "\n",
    "      except Exception as e:\n",
    "          print(f\"\\nError in sample {idx}:\")\n",
    "          print(f\"   Error type: {type(e).__name__}\")\n",
    "          print(f\"   Details: {str(e)}\")\n",
    "          if hasattr(e, '__cause__') and e.__cause__:\n",
    "              print(f\"   Underlying error: {type(e.__cause__).__name__}: {str(e.__cause__)}\")\n",
    "          print(f\"   DataFrame row:\\n{self.df.iloc[idx]}\")\n",
    "          return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5efb3-dabc-4f81-b3f9-2d65d4fbe7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized\n",
    "train_dataset = StyleDataset(df=train_df,processor=processor)\n",
    "eval_dataset= StyleDataset(df=eval_df,processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93628f6a-a378-4c80-a5d2-a8745c655a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3b92-0e22-4b3a-ae2c-cd13c153fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label string from encoding\n",
    "def get_label_str(encoding):\n",
    "  labels = encoding['labels']\n",
    "  labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "  label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "  return label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18974a92-fc3f-4b1e-9b62-1ec77af80a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "get_label_str(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd503a4-8051-49ea-b4a8-c9e6c8e2d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.iloc[0])\n",
    "show_image(train_df, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f386030-a888-493a-93ce-ef10097b8dd8",
   "metadata": {},
   "source": [
    "### 2.3 Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17936dd5-71b6-4e80-8e97-26f17fb6257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze your dataset first\n",
    "avg_target_len = training_df['text'].apply(len).mean()\n",
    "print(\"average target length\", avg_target_len)\n",
    "max_target_len = int(training_df['text'].apply(len).quantile(0.95))\n",
    "print(\"maximum target length\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fb7f5-3e36-4d9a-bec4-8bcc3c1a8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Alignment\n",
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8c70f-24ba-41c7-8933-6a3b0105cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=64,\n",
    "    early_stopping=True,\n",
    "    num_beams=4,\n",
    "    length_penalty=2.0,\n",
    "    no_repeat_ngram_size=3,\n",
    "    eos_token_id=processor.tokenizer.sep_token_id,\n",
    "    decoder_start_token_id=processor.tokenizer.cls_token_id,\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    skip_special_tokens=True  # Added for consistent decoding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34816fc-3bdc-4b85-ad98-981178c94e96",
   "metadata": {},
   "source": [
    "### 2.4 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1336000-01dc-412e-9b0e-4ed510e74ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "cer_metric = load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412c306-b040-4fa3-ba01-e39531cec4bb",
   "metadata": {},
   "source": [
    "## Step 3. Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742baafc-f4d5-4b3f-a265-961e33217a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    output_dir=\"./output/models/\",\n",
    "    logging_steps=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=200,\n",
    "    num_train_epochs=6,\n",
    "    generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(train_dataset):\n",
    "    if data is None or any(d is None for d in data.values()):\n",
    "        print(f\"None found in dataset at index {idx}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6d8ca-d8b1-4501-ba8a-0edda42aeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    processing_class=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()\n",
    "processor.save_pretrained(\"./output/models/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9ee3f",
   "metadata": {},
   "source": [
    "## Step 4. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf61b",
   "metadata": {},
   "source": [
    "### 4.1 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "from transformers import TrOCRProcessor\n",
    "model_path = \"./output/models/checkpoint-110333\"\n",
    "model =  VisionEncoderDecoderModel.from_pretrained(model_path).to(\"cuda\")\n",
    "# processor = TrOCRProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818867ad",
   "metadata": {},
   "source": [
    "### 4.2 Load Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf44cfe",
   "metadata": {},
   "source": [
    "### 4.3 Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec7186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def readText_batch(df, indices):\n",
    "    \"\"\"Process multiple images at once\"\"\"\n",
    "    #     subfolder = tokens[0].split('-')[0]\n",
    "    # subfolder2 = subfolder + \"-\" + tokens[0].split('-')[1]\n",
    "    # image_file_name = subfolder + \"\\\\\" + subfolder2 + \"\\\\\" + tokens[0] + \".png\"\n",
    "    # try:\n",
    "    #     with Image.open(os.path.join(image_file_path, image_file_name)) as img:\n",
    "    # subfolder = df['image_id'][indices[0]].split('\\\\')[0]\n",
    "    # subfolder2 = subfolder + \"-\" + df['image_id'][indices[0]].split('-')[1]\n",
    "    # image_dataset_path = os.path.join(image_file_path, subfolder, subfolder2, '')\n",
    "    paths = [df['image_id'].iloc[idx] for idx in indices]\n",
    "    images= [Image.open(path).convert(\"RGB\") for path in paths]\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    return processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "def process_all_rows_batched(df, batch_size=8):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches\"):\n",
    "        batch_indices = range(i, min(i+batch_size, len(df)))\n",
    "        try:\n",
    "            batch_texts = readText_batch(df, batch_indices)\n",
    "            for idx, text in zip(batch_indices, batch_texts):\n",
    "                results.append({\n",
    "                    'id': df['image_id'].iloc[idx],\n",
    "                    'preds': df['text'].iloc[idx],\n",
    "                    'labels': text\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size}: {str(e)}\")\n",
    "            for idx in batch_indices:\n",
    "                results.append({\n",
    "                    'id': df['image_id'].iloc[idx],\n",
    "                    'labels': df['text'].iloc[idx],\n",
    "                    'preds': None,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07465cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = process_all_rows_batched(test_df, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e969d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71788ed4",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f84a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "cer = load(\"cer\")\n",
    "\n",
    "def compute_eval_metrics(pred_str, label_str):\n",
    "    pred_str=pred_str.strip()\n",
    "    label_str=label_str.strip()\n",
    "    # max_len = max(len(pred_str), len(label_str))\n",
    "    # pred_str = pred_str.ljust(max_len)  \n",
    "    # label_str = label_str.ljust(max_len)\n",
    "    try: \n",
    "        score = cer.compute(predictions=[pred_str], references=[label_str])\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)\n",
    "        print(type(pred_str), len(pred_str), pred_str)\n",
    "        print(type(label_str), len(label_str), label_str)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # Enable progress_apply for pandas\n",
    "\n",
    "results_df[\"metrics\"] = results_df.progress_apply(\n",
    "    lambda row: compute_eval_metrics(row[\"preds\"], row[\"labels\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756051e",
   "metadata": {},
   "source": [
    "### 4.4 Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfa591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plot_eval(values):\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(values, shade=True)\n",
    "    plt.xlabel(\"Edit Distance\")\n",
    "    plt.title(\"KDE of Edit Distances\")\n",
    "    plt.show()\n",
    "        \n",
    "    # Boxplot\n",
    "    plt.boxplot(values, vert=False, patch_artist=True)\n",
    "    plt.xlabel(\"Edit Distance\")\n",
    "    plt.title(\"Boxplot of Edit Distances\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval(results_df[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da425bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "results_normal= results_df[results_df[\"metrics\"]<5]\n",
    "plot_eval(results_normal[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def show_state(values):\n",
    "    stats = {\n",
    "        \"mean\": np.mean(values),\n",
    "        \"median\": np.median(values),\n",
    "        \"std\": np.std(values),\n",
    "        \"min\": np.min(values),\n",
    "        \"max\": np.max(values),\n",
    "        \"quantiles\": np.quantile(values, [0.25, 0.5, 0.75]),\n",
    "        \"perfect\": np.sum(values == 0)\n",
    "\n",
    "    }\n",
    "    \n",
    "    print(\"Summary Statistics:\")\n",
    "    print(f\"- Mean ± Std: {stats['mean']:.2f} ± {stats['std']:.2f}\")\n",
    "    print(f\"- Median (IQR): {stats['median']:.2f} ({stats['quantiles'][0]:.2f}–{stats['quantiles'][2]:.2f})\")\n",
    "    print(f\"- Range: [{stats['min']}, {stats['max']}]\")\n",
    "    print(f\"- Quantiles (25th, 50th, 75th): {stats['quantiles'].round(2)}\")\n",
    "    print(f\"- Perfect Predictions: {stats['perfect']} ({stats['perfect']/len(values)*100:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa74880",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state(results_df[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
