{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89973f2d-b1f7-496b-8e37-68cb8dc7b713",
   "metadata": {},
   "source": [
    "## Process IAM Dataset\n",
    "Download the word image of IAM dataset from [Kaggle Dataset](https://www.kaggle.com/datasets/nibinv23/iam-handwriting-word-database), clean it and save training and testing set for consistant evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28f4eb-04a4-4fcb-a8fb-edd9bb1da9f8",
   "metadata": {},
   "source": [
    "## Step 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3e67b-4223-4755-b7f2-0b7718ba0218",
   "metadata": {},
   "source": [
    "### 1.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeca27-793b-4000-9f6b-b6a51debd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to your desired directory\n",
    "# os.chdir('/common/users/$USER/df_words') # change $USER to netid\n",
    "\n",
    "# Confirm it's changed\n",
    "# print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "images_dir = '.\\iam_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745fd7-48a8-461e-9780-b5e110b5b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "label_file_path = images_dir + '\\words.txt'\n",
    "image_file_path = images_dir + '\\iam_words\\words'\n",
    "\n",
    "data = []\n",
    "with open(label_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for idx, line in enumerate(lines[18:]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"Processing line {idx}\")\n",
    "    row = []\n",
    "    tokens = line.strip().split()\n",
    "    if len(tokens) < 2:\n",
    "        continue\n",
    "\n",
    "    subfolder = tokens[0].split('-')[0]\n",
    "    subfolder2 = subfolder + \"-\" + tokens[0].split('-')[1]\n",
    "    image_file_name = subfolder + \"\\\\\" + subfolder2 + \"\\\\\" + tokens[0] + \".png\"\n",
    "    image_path = os.path.join(image_file_path, image_file_name)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.size[0] >= 10 and img.size[1] >= 10:\n",
    "                img_rgb = img.convert(\"RGB\")  # Convert to RGB\n",
    "                img_copy = img_rgb.copy()     # Copy after conversion\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Image file not found: {image_file_path}. Error: {e}\")\n",
    "        continue\n",
    "    except Image.UnidentifiedImageError as e:\n",
    "        print(f\"Unidentified image error for file {image_file_path}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image file {image_file_path}: {e}\")\n",
    "        continue\n",
    "    row = [image_path, tokens[1], tokens[2], tokens[-1], img_copy]\n",
    "    # if len(row) != 10:\n",
    "    #     print(f\"Row length mismatch: {len(row)} elements in row: {row}\")\n",
    "    #     continue\n",
    "    data.append(row)\n",
    "\n",
    "\n",
    "print(f\"Length of a row in data: {len(data[0])}\")  # Should print 10\n",
    "\n",
    "print(data[0])\n",
    "loaded = pd.DataFrame(data, columns=['image_id', 'segmentation_status', 'graylevel','text', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410eee9-1cdb-4dae-b9eb-b8af757900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded.copy()\n",
    "print(loaded_dfwords.info())\n",
    "print(loaded_dfwords.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee3d00-f272-410f-8208-48a5f1851410",
   "metadata": {},
   "source": [
    "### 1.2 Show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a925a60-56a3-401e-98a6-b45d5ebfb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(df, row):\n",
    "    # plt.imshow(df.iloc[row]['image'], cmap='gray')\n",
    "    img = Image.open(df.iloc[row]['image_id'])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(loaded_dfwords, 10)  # Show the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae2b52-06a0-4910-86c4-cce65273b9d6",
   "metadata": {},
   "source": [
    "## Step 2. Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8f6ed-808d-4607-9104-9cb160d5ba87",
   "metadata": {},
   "source": [
    "### 2.1 Speical Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada98afd-f656-45dc-ab5f-edc0f3d24ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Patter for all Special characters\n",
    "special_char_pattern = r'[^a-zA-Z0-9\\s]'  # Matches anything not alphanumeric or whitespace\n",
    "\n",
    "# Select rows with special characters\n",
    "special_char_rows = loaded_dfwords[loaded_dfwords['text'].str.contains(special_char_pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497d1fb-a7fe-4d86-b527-b2d221ee4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4040a5a-2c6b-4942-81cc-78890fa1eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_pattern = r'^[\\w\\s\\.,!?;:\\-+*/=()\\[\\]{}<>@#\\$%^&_\\'\"\\t\\n]+$'\n",
    "mask = ~loaded_dfwords['text'].str.contains(allowed_pattern, regex=True)\n",
    "non_standard_rows = loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d01cd-5002-49da-bc64-e19ea134d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_standard_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6dc5b-8f26-40fe-9d3c-0dca648f4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = loaded_dfwords['text'].str.contains(r'\\\\', regex=True)\n",
    "check_rows= loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13879fc-095f-43b7-ad97-887bedc2fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords['text'] = loaded_dfwords['text'].str.replace('\\\\/', '/', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03450d73-c3c6-479e-a3a6-5ea1cb8401d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~loaded_dfwords['text'].str.contains(allowed_pattern, regex=True)\n",
    "non_standard_rows2 = loaded_dfwords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fed34-7601-4ea8-9f19-22450677186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words with special character:\", len(non_standard_rows2), \", Percentage: \", len(non_standard_rows2)/len(loaded_dfwords))\n",
    "print(\"Images with special character:\", len(non_standard_rows2['image_id'].unique()), \", Percentage: \", len(non_standard_rows2['image_id'].unique())/len(loaded_dfwords['image_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc85fe7-8168-4412-b128-86fcf0998657",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords=loaded_dfwords[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254f0e8-c135-45cc-957f-1ab94811e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbba6b3-8e22-4d0b-8811-10d61f31c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm there is no special characters\n",
    "count_matching = loaded_dfwords['text'].str.contains(allowed_pattern, regex=True, na=False).sum()\n",
    "print(f\"Number of rows with allowed characters: {count_matching}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875862b-c305-43e9-a435-94aebcd102ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^[^a-zA-Z0-9]+$'  # Matches strings with no alphanumeric chars at all\n",
    "non_alnum_rows = loaded_dfwords[loaded_dfwords['text'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f207856-f41e-42f2-919a-a0927287af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d632bdd-eee0-4ead-91cd-6db461c1d533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_alnum_rows.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfd214-526d-418b-8653-9d00f5bcd452",
   "metadata": {},
   "source": [
    "### 2.2 All-symbol Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06f40e-6f89-41b8-9ab3-78670b26c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check other rows that have only characters\n",
    "pattern = r'^[^a-zA-Z0-9]+$'  # Matches strings with no alphanumeric chars at all\n",
    "non_alnum_rows2 = loaded_dfwords[loaded_dfwords['text'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d544441-7107-493b-8d2d-877f20709bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alnum_rows2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alnum_rows2['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32292d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these to match the other imgur dataset preprocessing (it also removes all instances of text as '.' due to incorrect labels)\n",
    "only_period_rows= loaded_dfwords[loaded_dfwords['text'] == '.']\n",
    "loaded_dfwords = loaded_dfwords[loaded_dfwords['text'] != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyphen_row = loaded_dfwords[loaded_dfwords['text'] == '-----------------------------------------------------']\n",
    "id = hyphen_row['image_id'].to_string()\n",
    "print(id)\n",
    "print(\"image:\", id.split('\\\\')[-1])  # Print the image file name\n",
    "r = loaded_dfwords[loaded_dfwords['image_id'] == '.\\iam_words\\iam_words\\words\\p02\\p02-109\\p02-109-01-00.png']  # Get the row with the hyphen image\n",
    "print(r)\n",
    "show_image(r, 0)  # Show the hyphen image\n",
    "# show_image(loaded_dfwords, hyphen_row.index[0] + 1)  # Show the hyphen image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477aa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded_dfwords[loaded_dfwords['text'] != '-----------------------------------------------------']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords = loaded_dfwords.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf92f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dfwords.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de90b03-fec6-49d7-a5c2-a6e607766994",
   "metadata": {},
   "source": [
    "## Step 3. Splitting the Data into Training and Testing Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e89e37-29cc-4a1c-adcf-4f40216c0c8b",
   "metadata": {},
   "source": [
    "### 3.1 Spliting into Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35baa5f-4657-4390-b532-ee7ab81b6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get unique groups\n",
    "unique_images = loaded_dfwords['image_id'].unique()\n",
    "\n",
    "\n",
    "# Randomly select 10% for test \n",
    "np.random.seed(42)\n",
    "test_images = np.random.choice(unique_images, \n",
    "                              size=int(len(unique_images)*0.2), \n",
    "                              replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a2758-4458-4533-b933-d77fe786cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = loaded_dfwords[loaded_dfwords['image_id'].isin(test_images)]\n",
    "training_df = loaded_dfwords[~loaded_dfwords['image_id'].isin(test_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e759d-5504-4c81-a68c-f7154c2eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words in Train Dataset:\", len(training_df), \", Percentage: \", len(training_df)/len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6e047-453c-409e-98de-ce5ce73a9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words in Test Dataset:\", len(test_df), \", Percentage: \", len(test_df)/len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea129db7-c914-46cb-8f3c-79cd8390339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of words\", len(loaded_dfwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2346a-38db-41e0-9325-0d76229d2ee0",
   "metadata": {},
   "source": [
    "### 3.2 Saving the Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1113e1-f76e-49c5-aee4-6252107abdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df\n",
    "# train_df_copy = training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d34aa-944d-44d5-beee-731a5bb63d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy.drop('image', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca38c2-d716-4b17-80c9-dc8d6b57a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy.drop('image', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343bf93-f5b0-45a7-81d9-ba710fd3401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51113129-3240-404b-8ef7-20901c02bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ece9d-acc9-4cc0-8e48-a8c70286d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy.reset_index()\n",
    "# test_df_copy['word_id'] = test_df_copy.index\n",
    "# test_df_copy = test_df_copy.drop('index', axis=1)\n",
    "# test_df_copy = test_df_copy.drop('level_0', axis=1)\n",
    "\n",
    "# print(test_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8b101-6474-41ad-bafd-36de0412fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy.reset_index()\n",
    "# train_df_copy['word_id'] = train_df_copy.index\n",
    "# train_df_copy = train_df_copy.drop('index', axis=1)\n",
    "# train_df_copy = train_df_copy.drop('level_0', axis=1)\n",
    "\n",
    "# print(train_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53d1c0-2cc1-4007-b88e-4e52b990fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy = train_df_copy[[train_df_copy.columns[2]] + train_df_copy.columns[:2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb5fe2-91b8-440b-a15c-ac9b0ac103ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy = test_df_copy[[test_df_copy.columns[2]] + test_df_copy.columns[:2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e152858-71db-4fc7-93a9-a7dfa07c4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc20aa-8f0f-4327-8127-2e11fc0ffbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf5e9e-3de7-46ad-b458-4531b8a09a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c3dcc-f18b-4ad8-9ba0-86937200f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b327d-03a4-4c20-a875-2e192b81ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_copy.to_csv('df_test.csv', index=False)\n",
    "# train_df_copy.to_csv('df_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
